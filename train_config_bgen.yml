# Datasets are already TSV files
datasets:
  - test/data/bt.bgen.pls
  - test/data/clean.bgen.pls
  - test/data/medium.bgen.pls
  - test/data/dirty.bgen.pls
  - test/data/web.bgen.pls

stages:
  - bt
  - start
  - mid
  - end

bt:
  - bt.bgen.pls 0.8
  - clean.bgen.pls 0.2
  - medium.bgen.pls 0
  - dirty.bgen.pls 0
  - web.bgen.pls 0
  - until bt.bgen.pls 2

start:
  - bt.bgen.pls 0.1
  - clean.bgen.pls 0.7
  - medium.bgen.pls 2
  - dirty.bgen.pls 0
  - web.bgen.pls 0
  - until clean.bgen.pls 3

mid:
  - bt.bgen.pls 0
  - clean.bgen.pls 0.6
  - medium.bgen.pls 0.3
  - dirty.bgen.pls 0.1
  - web.bgen.pls 0
  - until medium.bgen.pls 1

end:
  - bt.bgen.pls 0
  - clean.bgen.pls 0.4
  - medium.bgen.pls 0.3
  - dirty.bgen.pls 0.2
  - web.bgen.pls 0.1
  - until dirty.bgen.pls 2

uppercase: 0.05
titlecase: 0.05
seed: 1111
trainer: /home/dheart/uni_stuff/postdoc/empty-train/trainer/test.py

# Settings for creating vocabulary
path_to_spm: /home/dheart/uni_stuff/postdoc/marian-dev/build/spm_train
vocab_size: 8000

vocab: /home/dheart/uni_stuff/postdoc/empty-train/trainer/test/vocab.bgen.spm
placeholder-symbol: "<PLACEHOLDER>"
num-placeholders: 4
regexes:
    - (https?:\/\/www\.\w{1,63}\.\w{1,63}(?:\/\w{0,63}){0,})
    - (www\.\w{1,63}\.\w{1,63}(?:\/\w{0,63}){0,})
    - ([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+)

